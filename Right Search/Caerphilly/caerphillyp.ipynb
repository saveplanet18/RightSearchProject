{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ff29b883",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "import os\n",
    "from colorama import Fore\n",
    "import time\n",
    "import openpyxl\n",
    "from openpyxl import Workbook\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4151d650",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "cannot assign to operator (Temp/ipykernel_10996/1372706980.py, line 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\yaraz\\AppData\\Local\\Temp/ipykernel_10996/1372706980.py\"\u001b[1;36m, line \u001b[1;32m16\u001b[0m\n\u001b[1;33m    sheet1.cell(row=count, column=1).value = \"Property Address:\" + user_input+ \"multiple Entries\".count=count+1\u001b[0m\n\u001b[1;37m                                             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m cannot assign to operator\n"
     ]
    }
   ],
   "source": [
    "def caerphilly(user_Address, url):\n",
    "    try:\n",
    "        driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "        driver.implicitly_wait(10)\n",
    "        driver.maximize_window()\n",
    "        print(Fore.LIGHTYELLOW_EX+\"Loading...\")\n",
    "        driver.get(url)\n",
    "        search_text  = driver.find_element(By.XPATH,\"//input[@id='simpleSearchString']\").send_keys(user_input)\n",
    "        time.sleep(2)\n",
    "        search_btn = driver.find_element(By.XPATH,\"//*[@id='simpleSearchForm']/div[3]/input[3]\").click() \n",
    "        time.sleep(2)\n",
    "        Myworksheet = Workbook()\n",
    "        sheet1 = Myworksheet.active\n",
    "        sheet1.title = \"sheet 1\"\n",
    "        count = 1\n",
    "        sheet1.cell(row=count, column=1).value = \"Property Address:\" + user_input\n",
    "        count=count+1\n",
    "        sheet1.cell(row=count, column=1).value = \"_____Summary_____\"\n",
    "        tab_relatedCases = driver.find_element(By.XPATH,'//*[@id=\"tab_relatedCases\"]').click()\n",
    "        time.sleep(2)\n",
    "        Erect_btn = driver.find_element(By.XPATH,'//*[@id=\"Property\"]/ul/li[1]/a').click()\n",
    "        time.sleep(2)\n",
    "        tab_relatedCases = driver.find_element(By.XPATH,'//*[@id=\"tab_relatedCases\"]').click()\n",
    "        time.sleep(2)\n",
    "        Application = driver.find_element(By.XPATH,'//*[@id=\"Application\"]/ul/li/a').click() \n",
    "        time.sleep(2)\n",
    "        webtable_df = driver.find_element_by_xpath('//*[@id=\"simpleDetailsTable\"]')\n",
    "        table_rows = webtable_df.find_elements_by_tag_name(\"tr\")\n",
    "        Mylist = [\"Reference\", \"Address\", \"Proposal\", \"Status\", \"Decision\", \"Decision Issued Date\", \"Appeal Status\",\"Appeal Decision\"]\n",
    "        for tr in table_rows:\n",
    "            thead = tr.find_element_by_tag_name(\"th\").text\n",
    "            if thead in Mylist:\n",
    "                tbody = tr.find_element_by_tag_name(\"td\").text\n",
    "                count = count + 1\n",
    "                sheet1.cell(row=count, column=1).value = thead+\":\"+tbody\n",
    "        count = count + 1\n",
    "        sheet1.cell(row=count, column=1).value = \"_____Important dates_____\"\n",
    "        subtab_dates = driver.find_element_by_xpath('//*[@id=\"subtab_dates\"]')\n",
    "        subtab_dates.click()  \n",
    "        simpleDetailsTable = driver.find_element_by_xpath('//*[@id=\"simpleDetailsTable\"]')\n",
    "        table_rows = simpleDetailsTable.find_elements_by_tag_name(\"tr\")\n",
    "        table_list=[\"Application Received Date\",\"Application Validated Date\",\"Decision Made Date\",\"Decision Issued Date\",\"Decision Printed Date\",\"Temporary Permission Expiry Date\"]\n",
    "        for tr in table_rows:\n",
    "            count = count + 1\n",
    "            thead = tr.find_element_by_tag_name(\"th\").text\n",
    "            if thead in table_list:\n",
    "                tbody = tr.find_element_by_tag_name(\"td\").text\n",
    "                sheet1.cell(row=count, column=1).value = thead+\":\"+tbody\n",
    "        address = user_input.strip()\n",
    "        Myworksheet.save(\"E:/Web Scrapping/Right Search/Caerphilly/\" + address + \".xlsx\")\n",
    "        driver.quit()\n",
    "        result = pd.read_excel(\"E:/Web Scrapping/Right Search/Caerphilly/\" + user_input + \".xlsx\",engine='openpyxl')\n",
    "        result.to_csv(\"E:/Web Scrapping/Right Search/Caerphilly/\" + user_input + \".csv\", index=None, header=True)\n",
    "        os.remove(\"E:/Web Scrapping/Right Search/Caerphilly/\" + user_input + \".xlsx\")\n",
    "        return 0\n",
    "    except Exception as catch:\n",
    "        return catch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a0069e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Property_address_path=\"E:\\Web Scrapping\\Right Search\\Data Capture Project - Responses\\LA List with Addresses.xlsx\"\n",
    "# wb=openpyxl.load_workbook(Property_address_path)\n",
    "# sh2 = wb.active\n",
    "# for r in range(1,sh2.max_row+2):\n",
    "#     for c in range(1,sh2.max_column+1):\n",
    "#         if (sh2.cell(row=1, column=c).value) == \"price\": \n",
    "#              if (sh2.cell(r+1,c).value or 0) > 500:\n",
    "#                 print(sh2.cell(r+1,c).value)\n",
    "#                 sh2.cell(r+1, c).fill = PatternFill(\"solid\",\"71FF35\")\n",
    "                \n",
    "# # wb.save(\"E:\\\\Web Scrapping\\\\Right Search\\\\Data Capture Project - Responses\\\\fullist.xlsx\")\n",
    "# # print(\"file Saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3f25d9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mylist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "704529f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRowcount(file,sheetname):\n",
    "    Workbook=openpyxl.load_workbook(file)\n",
    "    sheet = Workbook.get_sheet_by_name(sheetname)\n",
    "    return sheet.max_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "339c1251",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yaraz\\AppData\\Local\\Temp/ipykernel_848/3106231690.py:3: DeprecationWarning: Call to deprecated function get_sheet_by_name (Use wb[sheetname]).\n",
      "  sheet = Workbook.get_sheet_by_name(sheetname)\n"
     ]
    }
   ],
   "source": [
    "rows_count = getRowcount(Property_address_path,'Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ee8f2363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getColumncount(file,sheetname):\n",
    "    Workbook=openpyxl.load_workbook(file)\n",
    "    sheet = Workbook.get_sheet_by_name(sheetname)\n",
    "    return sheet.max_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8bf842a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yaraz\\AppData\\Local\\Temp/ipykernel_848/3192174779.py:3: DeprecationWarning: Call to deprecated function get_sheet_by_name (Use wb[sheetname]).\n",
      "  sheet = Workbook.get_sheet_by_name(sheetname)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getColumncount(Property_address_path,'Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c0c33027",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getReadData(file,sheetname,rownum,colnum):\n",
    "    Workbook=openpyxl.load_workbook(file)\n",
    "    sheet = Workbook.get_sheet_by_name(sheetname)\n",
    "    return sheet.cell(row=rownum,column=colnum).value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "98ac23ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def WriteData(file,sheetname,rownum,colnum):\n",
    "    Workbook=openpyxl.load_workbook(file)\n",
    "    sheet = Workbook.get_sheet_by_name(sheetname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7ff7366a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yaraz\\AppData\\Local\\Temp/ipykernel_848/1856426841.py:3: DeprecationWarning: Call to deprecated function get_sheet_by_name (Use wb[sheetname]).\n",
      "  sheet = Workbook.get_sheet_by_name(sheetname)\n"
     ]
    }
   ],
   "source": [
    "for count in range(1,rows_count+1):\n",
    "    Address = getReadData(Property_address_path,'Sheet1',count,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2e7fcdd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://property.swansea.gov.uk/online-applications/ '"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0eb77e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mTotal Addresses:\u001b[97m16\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "Property_address_path=\"E:\\Web Scrapping\\Right Search\\Data Capture Project - Responses\\LA List with Addresses.xlsx\"\n",
    "wb=openpyxl.load_workbook(Property_address_path)\n",
    "propertysheet=wb.active\n",
    "rows_count=propertysheet.max_row\n",
    "print(Fore.BLUE+\"Total Addresses:\"+Fore.LIGHTWHITE_EX+str(rows_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0ee99d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findpostal1(Address):#optional code if postalfinder website server is down we can use this but this is not an efficient one\n",
    "    if ', ' in Address:\n",
    "        x = Address.rsplit(\", \")\n",
    "        post=x[-1]\n",
    "        y = post.rsplit(\" \")\n",
    "        if len(y) > 1:\n",
    "            post=y[-2]\n",
    "    else:\n",
    "        if ',' in Address:\n",
    "            x = Address.rsplit(\",\")\n",
    "            post = x[-1]\n",
    "            y = post.rsplit(\" \")\n",
    "            if len(y) > 1:\n",
    "                post = y[-2]\n",
    "        else:\n",
    "            y =Address.rsplit(\" \")\n",
    "            post = y[-1]\n",
    "            if len(y) > 1:\n",
    "                post = y[-2]\n",
    "    if post.isalnum():\n",
    "        return post\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cfdc519b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findpostal(Address):\n",
    "    try:\n",
    "        driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "        driver.get(\"https://postcodefinder.net/\")\n",
    "        time.sleep(5)\n",
    "        wait = WebDriverWait(driver, 200)\n",
    "        textinput= driver.find_element(By.XPATH, \"// *[ @ id = 'wrapper'] / div[1] / div[2] / form / input\")\n",
    "        textinput.send_keys(Address)\n",
    "        textsubmit= driver.find_element(By.XPATH,\"// *[ @ id = 'wrapper'] / div[1] / div[2] / form / button\")\n",
    "        textsubmit.click()\n",
    "        time.sleep(3)\n",
    "        code= driver.find_element(By.XPATH,\"//*[@id='map']/div[1]/div[6]/div/div[1]/div/div[2]\")\n",
    "        post=code.text.strip(\"Postcode: \")\n",
    "        driver.close()\n",
    "        x = post.rsplit(\" \")\n",
    "        if len(x)>1:\n",
    "            post=x[-2]\n",
    "        if(post==\"unknown\"):\n",
    "            post=post+\" \"\n",
    "        if(post.isalnum()==True):\n",
    "            return post\n",
    "        else:\n",
    "            return 0\n",
    "    except Exception as e:\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2aa6743e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 98.0.4758\n",
      "Get LATEST chromedriver version for 98.0.4758 google-chrome\n",
      "Driver [C:\\Users\\yaraz\\.wdm\\drivers\\chromedriver\\win32\\98.0.4758.102\\chromedriver.exe] found in cache\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NameError(\"name 'WebDriverWait' is not defined\")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findpostal(Address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "697af9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findweblink(postalcode):\n",
    "    weblink=\"\"\n",
    "    Mapsheet_path = \"E:\\Web Scrapping\\Right Search\\Data Capture Project - Responses\\LA List with Addresses.xlsx\"\n",
    "    map_wb = openpyxl.load_workbook(Mapsheet_path)\n",
    "    map_propertysheet = map_wb.active\n",
    "    postalcode_maxrow = map_propertysheet.max_row\n",
    "    for i in range(1,postalcode_maxrow+1):\n",
    "        post_code = map_propertysheet.cell(row=i, column=1).value\n",
    "        post_code_list=post_code.rsplit(\",\")\n",
    "        post_code_list_len=len(post_code_list)\n",
    "        for b in range(0,post_code_list_len):\n",
    "            if(postalcode == post_code_list[b]):\n",
    "                weblink = weblink +\" \" +map_propertysheet.cell(row=i, column=2).value\n",
    "                return weblink\n",
    "    if(weblink==\"\"):\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "94f24c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findweblink('SA17 4TA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e4680cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resultt(count,result, Address):\n",
    "    if (result != 0):\n",
    "        print(Fore.LIGHTWHITE_EX+str(count) + \".\"+Address + Fore.RED + \" -oops Something went wrong while extracting planning applications\" + str(result))\n",
    "    else:\n",
    "        print(Fore.LIGHTWHITE_EX+str(count) + \".\" + Address + Fore.GREEN+\" -extracted successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b979d7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cardiff(Address,website):\n",
    "    try:\n",
    "        # Browser work\n",
    "        driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "        driver.get(website)\n",
    "        driver.maximize_window()\n",
    "        print(Fore.LIGHTYELLOW_EX+\"Loading...\")\n",
    "        driver.implicitly_wait(10)\n",
    "        time.sleep(5)\n",
    "        wait = WebDriverWait(driver, 200)\n",
    "        element = wait.until(EC.element_to_be_clickable((By.ID, \"atTextSearch\")))\n",
    "        time.sleep(8)\n",
    "        element.click()\n",
    "        element.send_keys(Address)\n",
    "        element2 = wait.until(EC.element_to_be_clickable((By.XPATH, \"//*[@id='searchForm']/input[2]\")))\n",
    "        element2.click()  # find\n",
    "        time.sleep(15)\n",
    "        element3 = wait.until(EC.element_to_be_clickable((By.XPATH, \"//*[@id='atLocationSearch']/p/div/ol/li/a\")))\n",
    "        element3.click()  # list\n",
    "        time.sleep(3)\n",
    "        element3 = wait.until(EC.element_to_be_clickable((By.XPATH, \"/html/body/div[2]/div[2]/div[2]/div[1]/form/div[3]/input[3]\")))\n",
    "        element3.click()  # my map\n",
    "        time.sleep(30)\n",
    "        env_check = wait.until(EC.element_to_be_clickable((By.XPATH, \"/html/body/div[6]/div/div/div/div/div[4]/div[2]/div[5]/h3/span[1]/input\")))\n",
    "        env_check.click()  # env\n",
    "        time.sleep(3)\n",
    "        plan = wait.until(EC.element_to_be_clickable((By.XPATH, \"/html/body/div[6]/div/div/div/div/div[4]/div[2]/div[7]/h3/span[1]/input\")))\n",
    "        plan.click()  # plan\n",
    "        time.sleep(30)\n",
    "        img = wait.until(EC.element_to_be_clickable((By.XPATH,\"/html/body/div[2]/div[2]/div[2]/div[1]/form/div[7]/div[1]/div/div/div[2]/div[1]/div[3]/div/img\")))\n",
    "        img.click()  # drop pin\n",
    "        time.sleep(15)\n",
    "        # for excel output\n",
    "        workbook = Workbook()\n",
    "        sheet1 = workbook.active\n",
    "        sheet1.title = \"sheet 1\"\n",
    "        row_count = 1\n",
    "        sheet1.cell(row=row_count, column=1).value = \"Property Address:\"+Address\n",
    "        row_count = row_count + 1\n",
    "        # copying data fields\n",
    "        popup = driver.find_element_by_xpath(\"//*[@class='atPopupFeatureInfo']\")\n",
    "        divs = popup.find_elements_by_tag_name('div')\n",
    "        for var in divs:\n",
    "            classname = var.get_attribute(\"class\")\n",
    "            if \"Planning-Applications\" in classname:\n",
    "                for z in var.find_elements_by_tag_name('div'):\n",
    "                    p = z.find_elements_by_tag_name(\"p\")\n",
    "                    for field in p:\n",
    "                        row_count = row_count + 1\n",
    "                        sheet1.cell(row=row_count, column=1).value = field.text\n",
    "\n",
    "        workbook.save(\"E:/Web Scrapping/Right Search/Caerphilly/\" + Address + \".xlsx\")\n",
    "        #CSV CONVERSION\n",
    "        data = pandas.read_excel(\"E:/Web Scrapping/Right Search/Caerphilly/\"+Address+\".xlsx\", engine='openpyxl')\n",
    "        data.to_csv(\"E:/Web Scrapping/Right Search/Caerphilly/\"+Address+\".csv\", index=None, header=True)\n",
    "        os.remove(\"E:/Web Scrapping/Right Search/Caerphilly/\"+Address+\".xlsx\")\n",
    "        driver.close()\n",
    "        return 0\n",
    "    except Exception as e:\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7ddc2d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def torfaen(Address, website):\n",
    "    try:\n",
    "        driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "        driver.get(website)\n",
    "        driver.maximize_window()\n",
    "        print(Fore.LIGHTYELLOW_EX+\"Loading...\")\n",
    "        driver.implicitly_wait(10)\n",
    "        time.sleep(5)\n",
    "        # select All\n",
    "        wait = WebDriverWait(driver, 150)\n",
    "        element = wait.until(EC.element_to_be_clickable((By.ID, \"searchTypeStatus\")))\n",
    "        drp = Select(element)\n",
    "        drp.select_by_visible_text(\"All\")\n",
    "        time.sleep(8)\n",
    "        # browser\n",
    "        wait = WebDriverWait(driver, 150)\n",
    "        element = wait.until(EC.element_to_be_clickable((By.ID, \"simpleSearchString\")))\n",
    "        element.click()\n",
    "        element.send_keys(Address)\n",
    "        element2 = wait.until(EC.element_to_be_clickable((By.XPATH, \"//*[@id='simpleSearchForm']/div[3]/input[3]\")))\n",
    "        element2.click()  # find\n",
    "        # for excel output\n",
    "        workbook = Workbook()\n",
    "        sheet1 = workbook.active\n",
    "        sheet1.title = \"sheet 1\"\n",
    "        row_count = 1\n",
    "        sheet1.cell(row=row_count, column=1).value = \"Property Address: \" + Address\n",
    "        row_count = row_count + 1\n",
    "        sheet1.cell(row=row_count, column=1).value = \"_____Summary_____\"\n",
    "        element4 = wait.until(EC.element_to_be_clickable((By.ID, \"simpleDetailsTable\")))\n",
    "        table_rows = element4.find_elements_by_tag_name(\"tr\")\n",
    "        Listy = [\"Reference\",\"Address\", \"Proposal\", \"Status\", \"Decision\", \"Decision Issued Date\",\"Appeal Status\",\"Appeal Decision\"]\n",
    "        for tr in table_rows:\n",
    "            thead = tr.find_element_by_tag_name(\"th\").text\n",
    "            if thead in Listy:\n",
    "                tbody = tr.find_element_by_tag_name(\"td\").text\n",
    "                content = thead + \":\" + tbody\n",
    "                # pasting the output in excel\n",
    "                row_count = row_count + 1\n",
    "                sheet1.cell(row=row_count, column=1).value = content\n",
    "        # extracting details\n",
    "        row_count = row_count + 1\n",
    "        sheet1.cell(row=row_count, column=1).value = \"_____Important Dates_____\"\n",
    "        element3 = wait.until(EC.element_to_be_clickable((By.ID, \"subtab_dates\")))\n",
    "        element3.click()  # find\n",
    "        element4 = wait.until(EC.element_to_be_clickable((By.ID, \"simpleDetailsTable\")))\n",
    "        table_rows = element4.find_elements_by_tag_name(\"tr\")\n",
    "        Listy=[\"Application Received Date\",\"Application Validated Date\",\"Decision Made Date\",\"Decision Issued Date\",\"Decision Printed Date\",\"Temporary Permission Expiry Date\"]\n",
    "        for tr in table_rows:\n",
    "            row_count = row_count + 1\n",
    "            thead = tr.find_element_by_tag_name(\"th\").text\n",
    "            if thead in Listy:\n",
    "                tbody = tr.find_element_by_tag_name(\"td\").text\n",
    "                content=thead+\":\"+tbody\n",
    "                # pasting the output in excel\n",
    "                sheet1.cell(row=row_count, column=1).value = content\n",
    "        address = Address.strip()\n",
    "        workbook.save(\"E:/Web Scrapping/Right Search/Caerphilly/\" + address + \".xlsx\")\n",
    "        #csv conversion\n",
    "        data = pandas.read_excel(\"E:/Web Scrapping/Right Search/Caerphilly/\" + address + \".xlsx\",engine='openpyxl')\n",
    "        data.to_csv(\"E:/Web Scrapping/Right Search/Caerphilly/\" + address + \".csv\", index=None, header=True)\n",
    "        os.remove(\"E:/Web Scrapping/Right Search/Caerphilly/\" + address + \".xlsx\")\n",
    "        driver.close()\n",
    "        return 0\n",
    "    except Exception as e:\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6f50b038",
   "metadata": {},
   "outputs": [],
   "source": [
    "def npt(Address, website):\n",
    "    try:\n",
    "        driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "        driver.get(website)\n",
    "        driver.maximize_window()\n",
    "        print(Fore.LIGHTYELLOW_EX+\"Loading...\")\n",
    "        driver.implicitly_wait(10)\n",
    "        time.sleep(5)\n",
    "           # browser\n",
    "        wait = WebDriverWait(driver, 150)\n",
    "        element = wait.until(EC.element_to_be_clickable((By.ID, \"simpleSearchString\")))\n",
    "        time.sleep(8)\n",
    "        element.click()\n",
    "        time.sleep(4)\n",
    "        element.send_keys(Address)\n",
    "        element2 = wait.until(EC.element_to_be_clickable((By.XPATH, \"//*[@id='simpleSearchForm']/div[3]/input[3]\")))\n",
    "        element2.click()  # find\n",
    "           # for excel output\n",
    "        workbook = Workbook()\n",
    "        sheet1 = workbook.active\n",
    "        sheet1.title = \"sheet 1\"\n",
    "        row_count = 1\n",
    "        sheet1.cell(row=row_count, column=1).value = \"Property Address:\" + Address\n",
    "           #summary\n",
    "        row_count = row_count+1\n",
    "        sheet1.cell(row=row_count, column=1).value = \"_____Summary_____\"\n",
    "        element4 = wait.until(EC.element_to_be_clickable((By.ID, \"simpleDetailsTable\")))\n",
    "        table_rows = element4.find_elements_by_tag_name(\"tr\")\n",
    "        Listy = [\"Reference\", \"Address\", \"Proposal\", \"Status\", \"Decision\", \"Decision Issued Date\", \"Appeal Status\",\"Appeal Decision\"]\n",
    "        for tr in table_rows:\n",
    "            thead = tr.find_element_by_tag_name(\"th\").text\n",
    "            if thead in Listy:\n",
    "                row_count = row_count + 1\n",
    "                tbody = tr.find_element_by_tag_name(\"td\").text\n",
    "                content = thead + \":\" + tbody\n",
    "                   # pasting the output in excel\n",
    "                sheet1.cell(row=row_count, column=1).value = content\n",
    "        row_count = row_count + 1\n",
    "        sheet1.cell(row=row_count, column=1).value = \"_____Important Dates_____\"\n",
    "        element3 = wait.until(EC.element_to_be_clickable((By.ID, \"subtab_dates\")))\n",
    "        element3.click()  # find\n",
    "           # extracting details\n",
    "        element4 = wait.until(EC.element_to_be_clickable((By.ID, \"simpleDetailsTable\")))\n",
    "        table_rows = element4.find_elements_by_tag_name(\"tr\")\n",
    "        Listy = [\"Application Received Date\", \"Application Validated Date\", \"Decision Made Date\", \"Decision Issued Date\",\"Decision Printed Date\",\"Temporary Permission Expiry Date\"]\n",
    "        for tr in table_rows:\n",
    "            row_count = row_count + 1\n",
    "            thead = tr.find_element_by_tag_name(\"th\").text\n",
    "            if thead in Listy:\n",
    "                tbody = tr.find_element_by_tag_name(\"td\").text\n",
    "                content=thead+\":\"+tbody\n",
    "                   # pasting the output in excel\n",
    "                sheet1.cell(row=row_count, column=1).value = content\n",
    "        address = Address.strip()\n",
    "        workbook.save(\"E:/Web Scrapping/Right Search/Caerphilly/\" + address + \".xlsx\")\n",
    "        data = pandas.read_excel(\"E:/Web Scrapping/Right Search/Caerphilly/\" + address + \".xlsx\",engine='openpyxl')\n",
    "        data.to_csv(\"E:/Web Scrapping/Right Search/Caerphilly/\" + address + \".csv\", index=None, header=True)\n",
    "        os.remove(\"E:/Web Scrapping/Right Search/Caerphilly/\" + address + \".xlsx\")\n",
    "        driver.close()\n",
    "        return 0\n",
    "    except Exception as e:\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c69de8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def powys(Address, website):\n",
    "    try:\n",
    "        driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "        driver.get(website)\n",
    "        driver.maximize_window()\n",
    "        print(Fore.LIGHTYELLOW_EX+\"Loading...\")\n",
    "        driver.implicitly_wait(10)\n",
    "        time.sleep(5)\n",
    "        # browser\n",
    "        wait = WebDriverWait(driver, 150)\n",
    "        element = wait.until(EC.element_to_be_clickable((By.ID, \"simpleSearchString\")))\n",
    "        time.sleep(8)\n",
    "        element.click()\n",
    "        time.sleep(10)\n",
    "        element.send_keys(Address)  \n",
    "        element2 = wait.until(EC.element_to_be_clickable((By.XPATH, \"//*[@id='simpleSearchForm']/div[4]/input[3]\")))\n",
    "        element2.click()  # find\n",
    "        # for excel output\n",
    "        workbook = Workbook()\n",
    "        sheet1 = workbook.active\n",
    "        sheet1.title = \"sheet 1\"\n",
    "        row_count = 1\n",
    "        sheet1.cell(row=row_count, column=1).value = \"Property Address:\" + Address\n",
    "        row_count = row_count+1\n",
    "        sheet1.cell(row=row_count, column=1).value = \"-----Summary-----\"\n",
    "        element4 = wait.until(EC.element_to_be_clickable((By.ID, \"simpleDetailsTable\")))\n",
    "        table_rows = element4.find_elements_by_tag_name(\"tr\")\n",
    "        Listy = [\"Reference\", \"Address\", \"Proposal\", \"Status\", \"Decision\", \"Decision Issued Date\", \"Appeal Status\",\"Appeal Decision\"]\n",
    "        for tr in table_rows:\n",
    "            thead = tr.find_element_by_tag_name(\"th\").text\n",
    "            if thead in Listy:\n",
    "                tbody = tr.find_element_by_tag_name(\"td\").text\n",
    "                content = thead + \":\" + tbody\n",
    "                # pasting the output in excel\n",
    "                row_count = row_count + 1\n",
    "                sheet1.cell(row=row_count, column=1).value = content\n",
    "        row_count = row_count + 1\n",
    "        sheet1.cell(row=row_count, column=1).value = \"-----Important Dates-----\"\n",
    "        element3 = wait.until(EC.element_to_be_clickable((By.ID, \"subtab_dates\")))\n",
    "        element3.click()  # find\n",
    "        # extracting details\n",
    "        element4 = wait.until(EC.element_to_be_clickable((By.ID, \"simpleDetailsTable\")))\n",
    "        table_rows = element4.find_elements_by_tag_name(\"tr\")\n",
    "        Listy=[\"Application Received Date\",\"Application Validated Date\",\"Decision Made Date\",\"Decision Issued Date\",\"Decision Printed Date\",\"Temporary Permission Expiry Date\"]\n",
    "        for tr in table_rows:\n",
    "            row_count = row_count + 1\n",
    "            thead = tr.find_element_by_tag_name(\"th\").text\n",
    "            if thead in Listy:\n",
    "                tbody = tr.find_element_by_tag_name(\"td\").text\n",
    "                content=thead+\":\"+tbody\n",
    "                # pasting the output in excel\n",
    "                sheet1.cell(row=row_count, column=1).value =content\n",
    "            address = Address.strip()\n",
    "        workbook.save(\"E:/Web Scrapping/Right Search/Caerphilly/\" + address + \".xlsx\")\n",
    "        # csv conversion\n",
    "        data = pandas.read_excel(\"E:/Web Scrapping/Right Search/Caerphilly/\" + address + \".xlsx\",engine='openpyxl')\n",
    "        data.to_csv(\"E:/Web Scrapping/Right Search/Caerphilly/\" + address + \".csv\", index=None, header=True)\n",
    "        os.remove(\"E:/Web Scrapping/Right Search/Caerphilly/\" + address + \".xlsx\")\n",
    "        driver.close()\n",
    "        return 0\n",
    "    except Exception as e:\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4a5252f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def carmarthenshire(Address, website):\n",
    "    try:\n",
    "        driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "        print(Fore.LIGHTYELLOW_EX + \"Loading...\")\n",
    "        driver.get(\"https://www.carmarthenshire.gov.wales/home/council-services/planning/search-for-a-planning-application/map-of-planning-applications/#.YKZfpKgzbIU\")\n",
    "        driver.implicitly_wait(10)\n",
    "        driver.maximize_window()\n",
    "        time.sleep(5)\n",
    "        wait = WebDriverWait(driver, 150)\n",
    "        save = wait.until(EC.element_to_be_clickable((By.ID, \"ccc-dismiss-button\")))\n",
    "        save.click()\n",
    "        time.sleep(5)\n",
    "        search = wait.until(EC.element_to_be_clickable((By.ID, \"postCodeSearchMap\")))\n",
    "        search.click()\n",
    "        time.sleep(5)\n",
    "        search.send_keys(Address)\n",
    "        time.sleep(40)\n",
    "        act=ActionChains(driver)\n",
    "        act.send_keys(Keys.ENTER).perform()\n",
    "        time.sleep(5)\n",
    "        li = wait.until(EC.element_to_be_clickable((By.XPATH, \"//*[@id='content']/div[2]/div[1]/div/div/div[2]/ul/li\")))\n",
    "        li.click()\n",
    "        time.sleep(20)\n",
    "        img = wait.until(EC.element_to_be_clickable((By.ID, \"OL_Icon_602_innerImage\")))\n",
    "        img.click()\n",
    "        time.sleep(5)\n",
    "        # for excel output\n",
    "        workbook = Workbook()\n",
    "        sheet1 = workbook.active\n",
    "        sheet1.title = \"sheet 1\"\n",
    "        row_count = 1\n",
    "        sheet1.cell(row=row_count, column=1).value = \"Property Address:\" + Address\n",
    "        popup = wait.until(EC.element_to_be_clickable((By.XPATH, \"//*[@id='idthatdoesntmatter_contentDiv']\")))\n",
    "        divs = popup.find_elements_by_tag_name(\"div\")\n",
    "        for var in divs:\n",
    "            classname = var.get_attribute(\"class\")\n",
    "            if \"call-out-row-\" in classname:\n",
    "                div = var.find_element_by_tag_name(\"div\")\n",
    "                row_count = row_count+1\n",
    "                sheet1.cell(row=row_count, column=1).value = div.text\n",
    "                table = var.find_element_by_tag_name(\"table\")\n",
    "                trs = table.find_elements_by_tag_name(\"tr\")\n",
    "                for var2 in trs:\n",
    "                    row_count = row_count + 1\n",
    "                    sheet1.cell(row=row_count, column=1).value = var2.text\n",
    "        workbook.save(\"C:/Users/Vidhya/Desktop/Rightsearchoutput/carmarthenshire/\" + Address + \".xlsx\")\n",
    "        # csv conversion\n",
    "        data = pandas.read_excel(\"E:/Web Scrapping/Right Search/Caerphilly/\" + Address + \".xlsx\", engine='openpyxl')\n",
    "        data.to_csv(\"E:/Web Scrapping/Right Search/Caerphilly/\" + Address + \".csv\", index=None, header=True)\n",
    "        os.remove(\"E:/Web Scrapping/Right Search/Caerphilly/\" + Address + \".xlsx\")\n",
    "        #driver.close()\n",
    "        return 0\n",
    "    except Exception as e:\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f3954fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rhondaa(Address, website):\n",
    "    try:\n",
    "        driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "        print(Fore.LIGHTYELLOW_EX+\"Loading...\")\n",
    "        driver.get(\"https://my.rctcbc.gov.uk/myRhondda.aspx?MapSource=RCT/AllMaps_english&amp;StartEasting=299818&amp;StartN\")\n",
    "        driver.implicitly_wait(10)\n",
    "        driver.maximize_window()\n",
    "        time.sleep(5)\n",
    "        wait = WebDriverWait(driver, 150)\n",
    "        my_maps = wait.until(EC.element_to_be_clickable((By.ID, \"atTabBar_btnTabRCT_-_AllMaps_english\")))\n",
    "        my_maps.click()\n",
    "        time.sleep(8)\n",
    "        textbox = wait.until(EC.element_to_be_clickable((By.ID, \"atTextSearch\")))\n",
    "        textbox.click()\n",
    "        time.sleep(3)\n",
    "        textbox.send_keys(Address)\n",
    "        find = wait.until(EC.element_to_be_clickable((By.XPATH, \"//*[@id='searchForm']/input[2]\")))\n",
    "        find.click()\n",
    "        time.sleep(3)\n",
    "        list = wait.until(EC.element_to_be_clickable((By.XPATH, \"//*[@id='atLocationSearch']/p/div/ol/li[1]/a\")))\n",
    "        list.click()\n",
    "        time.sleep(3)\n",
    "        check = wait.until(EC.element_to_be_clickable((By.XPATH, \"//*[@id='showmapcategories']/div[7]/h3/span[1]/input\")))\n",
    "        check.click()\n",
    "        time.sleep(10)\n",
    "        map_icon = wait.until(EC.element_to_be_clickable((By.ID, \"OL_Icon_121_innerImage\")))\n",
    "        map_icon.click()\n",
    "        time.sleep(3)\n",
    "        # for excel output\n",
    "        workbook = Workbook()\n",
    "        sheet1 = workbook.active\n",
    "        sheet1.title = \"sheet 1\"\n",
    "        sheet1.cell(row=1, column=1).value = \"Property Address\"+\":\"+Address\n",
    "        row_count = 1\n",
    "        # copying data\n",
    "        popup = driver.find_element_by_xpath(\"//*[@class='atPopupFeatureInfo']\")\n",
    "        divs = popup.find_elements_by_tag_name('div')\n",
    "        for var in divs:\n",
    "            classname = var.get_attribute(\"class\")\n",
    "            if \"Planning-Applications\" in classname:\n",
    "                for z in var.find_elements_by_tag_name('div'):\n",
    "                    for zz in z.find_elements_by_tag_name('p'):\n",
    "                        row_count = row_count + 1\n",
    "                        sheet1.cell(row=row_count, column=1).value = zz.text\n",
    "        address = Address.strip()\n",
    "        workbook.save(\"C:E:/Web Scrapping/Right Search/Caerphilly/\" + address + \".xlsx\")\n",
    "        # csv conversion\n",
    "        data = pandas.read_excel(\"E:/Web Scrapping/Right Search/Caerphilly/\" + address + \".xlsx\",engine='openpyxl')\n",
    "        data.to_csv(\"E:/Web Scrapping/Right Search/Caerphilly/\" + address + \".csv\", index=None,header=True)\n",
    "        os.remove(\"E:/Web Scrapping/Right Search/Caerphilly/\" + address + \".xlsx\")\n",
    "        driver.close()\n",
    "        return 0\n",
    "    except Exception as e:\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "98d05f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def monmouthshire(Address, website):\n",
    "    try:\n",
    "        driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "        print(Fore.LIGHTYELLOW_EX+\"Loading...\")\n",
    "        driver.get(\"https://maps.monmouthshire.gov.uk/localinfo.aspx\")\n",
    "        driver.maximize_window()\n",
    "        driver.implicitly_wait(10)\n",
    "        time.sleep(5)\n",
    "        wait = WebDriverWait(driver, 200)\n",
    "        Mymaps = wait.until(EC.element_to_be_clickable((By.XPATH, \"//*[@id='atTabBar_btnTabMonmouthshire_-_Monmouth']\")))\n",
    "        time.sleep(3)\n",
    "        Mymaps.click()\n",
    "        Textsearch = wait.until(EC.element_to_be_clickable((By.ID, \"atTextSearch\")))\n",
    "        Textsearch.click()\n",
    "        time.sleep(3)\n",
    "        Textsearch.send_keys(Address)\n",
    "        time.sleep(3)\n",
    "        find = wait.until(EC.element_to_be_clickable((By.XPATH, \"//*[@class='ui-state-default ui-corner-all atSearchBtn']\")))\n",
    "        find.click()\n",
    "        time.sleep(3)\n",
    "        list = wait.until(EC.element_to_be_clickable((By.XPATH, \"//*[@id='atLocationSearch']/p/div/ol/li[1]/a\")))\n",
    "        list.click()\n",
    "        time.sleep(3)\n",
    "        planning = wait.until(EC.element_to_be_clickable((By.XPATH, \"//*[@id='showmapcategories']/div[6]/h3/span[1]/input\")))\n",
    "        planning.click()\n",
    "        time.sleep(20)\n",
    "        img = wait.until(EC.element_to_be_clickable((By.XPATH, \"//*[@class='olAlphaImg']\")))\n",
    "        img.click()\n",
    "        time.sleep(8)\n",
    "        popup = wait.until(EC.element_to_be_clickable((By.XPATH, \"//*[@class='atPopupFeatureInfo']\")))\n",
    "        divs = popup.find_elements_by_tag_name('div')\n",
    "        flag = 0\n",
    "        count = 0\n",
    "        List = []\n",
    "        workbook = Workbook()\n",
    "        sheet1 = workbook.active\n",
    "        sheet1.title = \"sheet 1\"\n",
    "        row_count = 1\n",
    "        sheet1.cell(row=row_count, column=1).value = \"Property Address:\" + Address\n",
    "        for a in divs:\n",
    "            classname = a.get_attribute(\"class\")\n",
    "            if \"Planning-Applications\" in classname:\n",
    "                for z in a.find_elements_by_tag_name('div'):\n",
    "                    count = count + 1\n",
    "        for b in range(1, count + 1):\n",
    "            if (flag != 0):\n",
    "                img = wait.until(EC.element_to_be_clickable((By.XPATH, \"//*[@class='olAlphaImg']\")))\n",
    "                time.sleep(3)\n",
    "                img.click()\n",
    "                time.sleep(8)  # //*[@id=\"OpenLayers.Popup.FramedCompact_146_contentDiv\"]/div/div/div[1]/p/strong[2]/a\n",
    "            flag = 1\n",
    "            row_count = row_count + 1\n",
    "            sheet1.cell(row=row_count, column=1).value = \" \"\n",
    "            row_count=row_count+1\n",
    "            sheet1.cell(row=row_count, column=1).value = \"_____Result\" + str(b)+\"_____\"\n",
    "            row_count = row_count + 1\n",
    "            sheet1.cell(row=row_count, column=1).value = \"_____Summary_____\"\n",
    "            App = driver.find_element_by_xpath(\"//*[@class='atPopupFeatureInfo'] / div / div[\" + str(b) + \"]\")\n",
    "            App.click()\n",
    "            time.sleep(5)\n",
    "            table = wait.until(EC.element_to_be_clickable((By.ID, \"simpleDetailsTable\")))\n",
    "            table_rows = table.find_elements_by_tag_name(\"tr\")\n",
    "            Listy = [\"Reference\", \"Address\", \"Proposal\", \"Status\", \"Decision\", \"Decision Issued Date\", \"Appeal Status\",\"Appeal Decision\"]\n",
    "            for tr in table_rows:\n",
    "                row_count = row_count + 1\n",
    "                thead = tr.find_element_by_tag_name(\"th\").text\n",
    "                if thead in Listy:\n",
    "                    tbody = tr.find_element_by_tag_name(\"td\").text\n",
    "                    sheet1.cell(row=row_count, column=1).value = thead + \":\" + tbody\n",
    "            row_count = row_count + 1\n",
    "            sheet1.cell(row=row_count, column=1).value = \"_____Important Dates_____\"\n",
    "            try:\n",
    "                imp_dates = wait.until(EC.element_to_be_clickable((By.XPATH, \"//*[@id='subtab_dates']\")))\n",
    "            except Exception as e:\n",
    "                ex=\"Planning Applications not available\"\n",
    "                return ex\n",
    "            imp_dates.click()\n",
    "            table = wait.until(EC.element_to_be_clickable((By.ID, \"simpleDetailsTable\")))\n",
    "            table_rows = table.find_elements_by_tag_name(\"tr\")\n",
    "            Listy = [\"Application Received Date\", \"Application Validated Date\", \"Decision Made Date\",\"Decision Issued Date\", \"Decision Printed Date\",\"Temporary Permission Expiry Date\"]\n",
    "            for tr in table_rows:\n",
    "                row_count = row_count + 1\n",
    "                thead = tr.find_element_by_tag_name(\"th\").text\n",
    "                if thead in Listy:\n",
    "                    tbody = tr.find_element_by_tag_name(\"td\").text\n",
    "                    sheet1.cell(row=row_count, column=1).value = thead+\":\"+tbody\n",
    "            row_count = row_count + 1\n",
    "            sheet1.cell(row=row_count, column=1).value = \" \"\n",
    "            workbook.save(\"E:/Web Scrapping/Right Search/Caerphilly/\" + Address + \".xlsx\")\n",
    "            driver.back()\n",
    "            driver.back()\n",
    "            time.sleep(10)\n",
    "        driver.close()\n",
    "        # csv conversion\n",
    "        data = pandas.read_excel(\"E:/Web Scrapping/Right Search/Caerphilly/\" + Address + \".xlsx\",engine='openpyxl')\n",
    "        data.to_csv(\"E:/Web Scrapping/Right Search/Caerphilly/\" + Address + \".csv\", index=None, header=True)\n",
    "        os.remove(\"E:/Web Scrapping/Right Search/Caerphilly/\" + Address + \".xlsx\")\n",
    "        return 0\n",
    "    except Exception as e:\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "46e74e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bridgend(Address, website):\n",
    "    try:\n",
    "        driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "        print(Fore.LIGHTYELLOW_EX+\"Loading...\")\n",
    "        driver.get(\"http://planning.bridgend.gov.uk/\")\n",
    "        driver.maximize_window()\n",
    "        driver.implicitly_wait(10)\n",
    "        time.sleep(5)\n",
    "        wait = WebDriverWait(driver, 150)\n",
    "        agree = wait.until(EC.element_to_be_clickable((By.XPATH, \"//*[@id='main-content']/div/div/section/div/div/div/div/form/div/input\")))\n",
    "        time.sleep(8)\n",
    "        agree.click()\n",
    "        time.sleep(4)\n",
    "        textbox = wait.until(EC.element_to_be_clickable((By.ID, \"SearchParams_Address\")))\n",
    "        time.sleep(3)\n",
    "        textbox.click()\n",
    "        textbox.send_keys(Address)\n",
    "        search = wait.until(EC.element_to_be_clickable((By.XPATH, \"//*[@id='main-content']/div/div/section/div/div/div/div/form/div[2]/input[1]\")))\n",
    "        time.sleep(3)\n",
    "        search.click()\n",
    "        time.sleep(7)\n",
    "        table_responsive = driver.find_element_by_class_name(\"table-responsive\")\n",
    "        body_of_table = table_responsive.find_element_by_tag_name(\"tbody\")\n",
    "        rows = body_of_table.find_elements_by_tag_name(\"tr\")\n",
    "        count = 0\n",
    "        for row in rows:\n",
    "            count = count + 1\n",
    "        # for excel output\n",
    "        workbook = Workbook()\n",
    "        sheet1 = workbook.active\n",
    "        sheet1.title = \"sheet 1\"\n",
    "        row_count = 1\n",
    "        sheet1.cell(row=row_count, column=1).value = \"Property Address:\" + Address\n",
    "        for row in range(1, count + 1):\n",
    "            row_count=row_count+1\n",
    "            sheet1.cell(row=row_count, column=1).value = \"______Result\"+str(row)+\"_____\"\n",
    "            link = driver.find_element_by_xpath(\"//*[@id='main-content']/div/div/section/div/div/div/div/div[2]/table/tbody/tr[\" + str(row) + \"]/td[1]/a\")\n",
    "            link.click()\n",
    "            time.sleep(5)\n",
    "            wait = WebDriverWait(driver, 150)\n",
    "            t = wait.until(EC.element_to_be_clickable((By.CLASS_NAME, \"table-responsive\")))\n",
    "            body = t.find_element_by_tag_name(\"tbody\")\n",
    "            rs = body.find_elements_by_tag_name(\"tr\")\n",
    "            for t_row in rs:\n",
    "                row_count = row_count + 1\n",
    "                tdatas = t_row.find_elements_by_tag_name(\"td\")\n",
    "                sheet1.cell(row=row_count, column=1).value = tdatas[0].text+\":\"+tdatas[1].text\n",
    "            workbook.save(\"E:/Web Scrapping/Right Search/Caerphilly/\" + Address + \".xlsx\")\n",
    "            driver.back()\n",
    "        driver.close()\n",
    "        #csv conversion\n",
    "        data = pandas.read_excel(\"E:/Web Scrapping/Right Search/Caerphilly/\" + Address + \".xlsx\",engine='openpyxl')\n",
    "        data.to_csv(\"E:/Web Scrapping/Right Search/Caerphilly/\" + Address + \".csv\", index=None,header=True)\n",
    "        os.remove(\"E:/Web Scrapping/Right Search/Caerphilly/\" + Address + \".xlsx\")\n",
    "        return 0\n",
    "    except Exception as e:\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2cc23517",
   "metadata": {},
   "outputs": [],
   "source": [
    "def newport(Address, website):\n",
    "    try:\n",
    "        driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "        print(Fore.LIGHTYELLOW_EX+\"Loading...\")\n",
    "        driver.get(website)\n",
    "        driver.maximize_window()\n",
    "        driver.implicitly_wait(10)\n",
    "        time.sleep(5)\n",
    "        wait = WebDriverWait(driver, 150)\n",
    "        my_maps = wait.until(EC.element_to_be_clickable((By.ID, \"atTabBar_btnTabmapsources_-_AllMaps\")))\n",
    "        my_maps.click()\n",
    "        time.sleep(8)\n",
    "        textbox = wait.until(EC.element_to_be_clickable((By.ID, \"atTextSearch\")))\n",
    "        textbox.click()\n",
    "        time.sleep(3)\n",
    "        textbox.send_keys(Address)\n",
    "        time.sleep(3)\n",
    "        find = driver.find_element_by_xpath(\"/html/body/div[1]/div[1]/form/div[4]/div/p/form/input[2]\")\n",
    "        find.click()\n",
    "        time.sleep(3)\n",
    "        list = wait.until(EC.element_to_be_clickable((By.XPATH, \"//*[@id='id_aw_results']/ol/li[1]/a\")))\n",
    "        list.click()\n",
    "        time.sleep(3)\n",
    "        check = wait.until(EC.element_to_be_clickable((By.XPATH, \"//*[@id='showmapcategories']/div[6]/h3/span[1]/input\")))\n",
    "        check.click()\n",
    "        time.sleep(3)\n",
    "        map_icon = wait.until(EC.element_to_be_clickable((By.ID, \"OL_Icon_117_innerImage\")))\n",
    "        map_icon.click()\n",
    "        time.sleep(3)\n",
    "        # for excel output\n",
    "        workbook = Workbook()\n",
    "        sheet1 = workbook.active\n",
    "        sheet1.title = \"sheet 1\"\n",
    "        row_count = 1\n",
    "        sheet1.cell(row=row_count, column=1).value = \"Property Address:\"+Address\n",
    "        # copying data\n",
    "        popup = driver.find_element_by_xpath(\"//*[@class='atPopupFeatureInfo']\")\n",
    "        divs = popup.find_elements_by_tag_name('div')\n",
    "        for var in divs:\n",
    "            classname = var.get_attribute(\"class\")\n",
    "            if \"Planning-Applications\" in classname:\n",
    "                for z in var.find_elements_by_tag_name('div'):\n",
    "                    for zz in z.find_elements_by_tag_name('p'):\n",
    "                        row_count = row_count + 1\n",
    "                        sheet1.cell(row=row_count, column=1).value = zz.text\n",
    "        address = Address.strip()\n",
    "        workbook.save(\"C:/Users/Vidhya/Desktop/Rightsearchoutput/Newport/\" + address + \".xlsx\")\n",
    "        driver.close()\n",
    "        # csv conversion\n",
    "        data = pandas.read_excel(\"E:/Web Scrapping/Right Search/Caerphilly/\" + Address + \".xlsx\",engine='openpyxl')\n",
    "        data.to_csv(\"E:/Web Scrapping/Right Search/Caerphilly/\" + Address + \".csv\", index=None, header=True)\n",
    "        os.remove(\"E:/Web Scrapping/Right Search/Caerphilly/\" + Address + \".xlsx\")\n",
    "        return 0\n",
    "    except Exception as e:\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4307f0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def glamorgan(Address, website):\n",
    "    try:\n",
    "        driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "        driver.get(website)\n",
    "        driver.maximize_window()\n",
    "        print(Fore.LIGHTYELLOW_EX+\"Loading...\")\n",
    "        driver.implicitly_wait(10)\n",
    "        time.sleep(5)\n",
    "       # browser work\n",
    "        wait = WebDriverWait(driver, 200)\n",
    "        My_maps = wait.until(EC.element_to_be_clickable((By.ID, \"atTabBar_btnTabValeOfGlamorgan_-_AllMaps\")))\n",
    "        My_maps.click()\n",
    "        time.sleep(5)\n",
    "        search = wait.until(EC.element_to_be_clickable((By.ID, \"atTextSearch\")))\n",
    "        search.send_keys(Address)\n",
    "        time.sleep(5)\n",
    "        find = wait.until(EC.element_to_be_clickable((By.XPATH, \"/html/body/div[2]/form/div[4]/div/p/form/input[2]\")))\n",
    "        find.click()\n",
    "        time.sleep(5)\n",
    "        list = wait.until(EC.element_to_be_clickable((By.XPATH, \"//*[@id='id_aw_results']/ol/li/a\")))\n",
    "        list.click()\n",
    "        time.sleep(5)\n",
    "        check = wait.until(EC.element_to_be_clickable((By.XPATH, \"//*[@id='showmapcategories']/div[9]/h3/span[1]/input\")))\n",
    "        check.click()\n",
    "        time.sleep(5)\n",
    "        icon = wait.until(EC.element_to_be_clickable((By.ID, \"OL_Icon_121_innerImage\")))\n",
    "        icon.click()  # //*[@id=\"OL_Icon_121_innerImage\"]\n",
    "        time.sleep(10)\n",
    "       # for excel output\n",
    "        workbook = Workbook()\n",
    "        sheet1 = workbook.active\n",
    "        sheet1.title = \"sheet 1\"\n",
    "        row_count = 1\n",
    "        sheet1.cell(row=row_count, column=1).value = \"Property Address:\"+Address\n",
    "       # copying data\n",
    "        popup = driver.find_element_by_xpath(\"//*[@class='atPopupFeatureInfo']\")\n",
    "        divs = popup.find_elements_by_tag_name('div')\n",
    "        flag = 0\n",
    "        for var in divs:\n",
    "            classname = var.get_attribute(\"class\")\n",
    "            if \"Planning-Applications\" in classname:\n",
    "                flag = 1\n",
    "                for z in var.find_elements_by_tag_name('div'):\n",
    "                    p = z.find_elements_by_tag_name(\"p\")\n",
    "                    for field in p:\n",
    "                        row_count=row_count+1\n",
    "                        sheet1.cell(row=row_count, column=1).value = field.text\n",
    "        if (flag == 0):\n",
    "            sheet1.cell(row=2, column=1).value = \"Planning applications not available for this address\"\n",
    "        address = Address.strip()\n",
    "        workbook.save(\"E:/Web Scrapping/Right Search/Caerphilly/\" + address + \".xlsx\")\n",
    "        driver.close()\n",
    "       # csv conversion\n",
    "        data = pandas.read_excel(\"E:/Web Scrapping/Right Search/Caerphilly/\" + address + \".xlsx\", engine='openpyxl')\n",
    "        data.to_csv(\"E:/Web Scrapping/Right Search/Caerphilly/\" + address + \".csv\", index=None, header=True)\n",
    "        os.remove(\"E:/Web Scrapping/Right Search/Caerphilly/\" + address + \".xlsx\")\n",
    "        return 0\n",
    "    except Exception as e:\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bb9bc29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merthyrTydfill(Address, website):\n",
    "    try:\n",
    "        driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "        driver.get(website)\n",
    "        driver.maximize_window()\n",
    "        print(Fore.LIGHTYELLOW_EX+\"Loading...\")\n",
    "        driver.implicitly_wait(10)\n",
    "        time.sleep(5)\n",
    "        # select All\n",
    "        wait = WebDriverWait(driver, 150)\n",
    "        element = wait.until(EC.element_to_be_clickable((By.ID, \"searchTypeStatus\")))\n",
    "        drp = Select(element)\n",
    "        drp.select_by_visible_text(\"All\")\n",
    "        time.sleep(8)\n",
    "        # browser\n",
    "        wait = WebDriverWait(driver, 150)\n",
    "        element = wait.until(EC.element_to_be_clickable((By.ID, \"simpleSearchString\")))\n",
    "        time.sleep(8)\n",
    "        element.click()\n",
    "        time.sleep(4)\n",
    "        element.send_keys(Address)\n",
    "        element2 = wait.until(EC.element_to_be_clickable((By.XPATH, \"//*[@id='simpleSearchForm']/div[3]/input[3]\")))\n",
    "        element2.click()  # find\n",
    "\n",
    "        # for excel output\n",
    "        workbook = Workbook()\n",
    "        sheet1 = workbook.active\n",
    "        sheet1.title = \"sheet 1\"\n",
    "        row_count = 1\n",
    "        sheet1.cell(row=row_count, column=1).value =\"Property Address:\"+Address\n",
    "        row_count=row_count+1\n",
    "        sheet1.cell(row=row_count, column=1).value = \"_____Summary_____\"\n",
    "        element4 = wait.until(EC.element_to_be_clickable((By.ID, \"simpleDetailsTable\")))\n",
    "        table_rows = element4.find_elements_by_tag_name(\"tr\")\n",
    "        Listy = [\"Reference\", \"Address\", \"Proposal\", \"Status\", \"Decision\", \"Decision Issued Date\", \"Appeal Status\",\"Appeal Decision\"]\n",
    "        for tr in table_rows:\n",
    "            thead = tr.find_element_by_tag_name(\"th\").text\n",
    "            if thead in Listy:\n",
    "                tbody = tr.find_element_by_tag_name(\"td\").text\n",
    "                # pasting the output in excel\n",
    "                row_count = row_count + 1\n",
    "                sheet1.cell(row=row_count, column=1).value = thead + \":\" + tbody\n",
    "        row_count = row_count + 1\n",
    "        sheet1.cell(row=row_count, column=1).value = \"_____Important Dates_____\"\n",
    "        # extracting details\n",
    "        element3 = wait.until(EC.element_to_be_clickable((By.ID, \"subtab_dates\")))\n",
    "        element3.click()\n",
    "        element4 = wait.until(EC.element_to_be_clickable((By.ID, \"simpleDetailsTable\")))\n",
    "        table_rows = element4.find_elements_by_tag_name(\"tr\")\n",
    "        Listy=[\"Application Received Date\",\"Application Validated Date\",\"Decision Made Date\",\"Decision Issued Date\",\"Decision Printed Date\",\"Temporary Permission Expiry Date\"]\n",
    "        for tr in table_rows:\n",
    "            thead = tr.find_element_by_tag_name(\"th\").text\n",
    "            if thead in Listy:\n",
    "                tbody = tr.find_element_by_tag_name(\"td\").text\n",
    "                    # pasting the output in excel\n",
    "                row_count = row_count + 1\n",
    "                sheet1.cell(row=row_count, column=1).value =thead+\":\"+tbody\n",
    "        address = Address.strip()\n",
    "        workbook.save(\"E:/Web Scrapping/Right Search/Caerphilly/\" + address + \".xlsx\")\n",
    "        driver.close()\n",
    "        #csv conversion\n",
    "        data = pandas.read_excel(\"E:/Web Scrapping/Right Search/Caerphilly/\" + address + \".xlsx\",engine='openpyxl')\n",
    "        data.to_csv(\"E:/Web Scrapping/Right Search/Caerphilly/\" + address + \".csv\", index=None,header=True)\n",
    "        os.remove(\"E:/Web Scrapping/Right Search/Caerphilly/\" + address + \".xlsx\")\n",
    "        return 0\n",
    "    except Exception as e:\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6e828724",
   "metadata": {},
   "outputs": [],
   "source": [
    "def swansea(Address, website):\n",
    "    try:\n",
    "        driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "        print(Fore.LIGHTYELLOW_EX+\"Loading...\")\n",
    "        driver.get(website)\n",
    "        driver.maximize_window()\n",
    "        driver.implicitly_wait(10)\n",
    "        time.sleep(5)\n",
    "        wait = WebDriverWait(driver, 150)\n",
    "        textbox = wait.until(EC.element_to_be_clickable((By.ID, \"simpleSearchString\")))\n",
    "        time.sleep(8)\n",
    "        textbox.click()\n",
    "        time.sleep(4)\n",
    "        textbox.send_keys(Address)  # //*[@id=\"simpleSearchForm\"]/div[3]/input[3]\n",
    "        find = wait.until(EC.element_to_be_clickable((By.XPATH, \"//*[@id='simpleSearchForm']/div[3]/input[3]\")))\n",
    "        find.click()  # find\n",
    "        time.sleep(5)\n",
    "        results_container = driver.find_element_by_id(\"searchResultsContainer\")\n",
    "        ul = results_container.find_elements_by_tag_name(\"li\")\n",
    "        # for excel output\n",
    "        workbook = Workbook()\n",
    "        sheet1 = workbook.active\n",
    "        sheet1.title = \"sheet 1\"\n",
    "        row_count = 1\n",
    "        sheet1.cell(row=1, column=1).value = \"Property Address:\" + Address\n",
    "        for li in range(1, len(ul) + 1):\n",
    "            row_count = row_count + 1\n",
    "            sheet1.cell(row=row_count, column=1).value =\"__________Result\"+ str(li)+\"__________\"\n",
    "            link = driver.find_element_by_xpath(\"//*[@id='searchresults']/li[\" + str(li) + \"]/a\")\n",
    "            link.click()\n",
    "            time.sleep(3)\n",
    "            row_count=row_count+1\n",
    "            sheet1.cell(row=row_count, column=1).value = \"_____Summary_____\"\n",
    "            element4 = wait.until(EC.element_to_be_clickable((By.ID, \"simpleDetailsTable\")))\n",
    "            table_rows = element4.find_elements_by_tag_name(\"tr\")\n",
    "            Listy = [\"Reference\", \"Address\", \"Proposal\", \"Status\", \"Decision\", \"Decision Issued Date\", \"Appeal Status\",\"Appeal Decision\"]\n",
    "            for t in table_rows:\n",
    "                thead = t.find_element_by_tag_name(\"th\").text\n",
    "                if thead in Listy:\n",
    "                    tbody = t.find_element_by_tag_name(\"td\").text\n",
    "                    row_count = row_count + 1\n",
    "                    sheet1.cell(row=row_count, column=1).value = thead + \":\" + tbody\n",
    "            row_count = row_count + 1\n",
    "            sheet1.cell(row=row_count, column=1).value = \"_____Important Dates_____\"\n",
    "            element3 = wait.until(EC.element_to_be_clickable((By.ID, \"subtab_dates\")))\n",
    "            element3.click()  # find\n",
    "            element4 = wait.until(EC.element_to_be_clickable((By.ID, \"simpleDetailsTable\")))\n",
    "            table_rows = element4.find_elements_by_tag_name(\"tr\")\n",
    "            Listy = [\"Application Received Date\", \"Application Validated Date\", \"Decision Made Date\",\"Decision Issued Date\", \"Decision Printed Date\",\"Temporary Permission Expiry Date\"]\n",
    "            for t in table_rows:\n",
    "                thead = t.find_element_by_tag_name(\"th\").text\n",
    "                if thead in Listy:\n",
    "                    tbody = t.find_element_by_tag_name(\"td\").text\n",
    "                    row_count = row_count + 1\n",
    "                    sheet1.cell(row=row_count, column=1).value = thead+\":\"+tbody\n",
    "            workbook.save(\"E:/Web Scrapping/Right Search/Caerphilly/\" + Address + \".xlsx\")\n",
    "            driver.back()\n",
    "            driver.back()\n",
    "        driver.close()\n",
    "        #csv conversion\n",
    "        data = pandas.read_excel(\"E:/Web Scrapping/Right Search/Caerphilly/\" + Address + \".xlsx\",engine='openpyxl')\n",
    "        data.to_csv(\"E:/Web Scrapping/Right Search/Caerphilly/\" + Address + \".csv\", index=None, header=True)\n",
    "        os.remove(\"E:/Web Scrapping/Right Search/Caerphilly/\" + Address + \".xlsx\")\n",
    "        return 0\n",
    "    except Exception as e:\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c0ab1be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pembrokeshire(Address, website):\n",
    "    try:\n",
    "        driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "        print(\"Loading...\")\n",
    "        driver.get(website)\n",
    "        driver.implicitly_wait(10)\n",
    "        driver.maximize_window()\n",
    "        time.sleep(5)\n",
    "        wait = WebDriverWait(driver, 150)\n",
    "        textbox = wait.until(EC.element_to_be_clickable((By.NAME, \"JUSTLOCATION.MAINBODY.WPACIS.1\")))\n",
    "        time.sleep(3)\n",
    "        textbox.click()\n",
    "        textbox.send_keys(Address)\n",
    "        search = wait.until(EC.element_to_be_clickable((By.XPATH, \"//*[@id='apas_form']/fieldset[3]/input\")))\n",
    "        time.sleep(3)\n",
    "        search.click()\n",
    "        time.sleep(7)\n",
    "        table = driver.find_element_by_class_name(\"apas_tbl\")\n",
    "        rows = table.find_elements_by_tag_name(\"tr\")\n",
    "        county = 0\n",
    "        for row in rows:\n",
    "            county = county + 1\n",
    "        # for excel output\n",
    "        workbook = Workbook()\n",
    "        sheet1 = workbook.active\n",
    "        sheet1.title = \"sheet 1\"\n",
    "        row_count = 1\n",
    "        sheet1.cell(row=1, column=1).value = \"Property Address:\" + Address\n",
    "        for row in range(2, county + 1):\n",
    "            row_count=row_count+1\n",
    "            sheet1.cell(row=row_count, column=1).value = \"Result\"+str(row-1)\n",
    "            link = driver.find_element_by_xpath(\"// *[ @ id = 'apas_form'] / table / tbody / tr[\" + str(row) + \"] / td[1] / a\")\n",
    "            link.click()\n",
    "            time.sleep(3)\n",
    "            div1 = driver.find_element_by_class_name(\"apas\")\n",
    "            div1s = div1.find_elements_by_tag_name(\"div\")\n",
    "            row_count = row_count + 1\n",
    "            sheet1.cell(row=row_count , column=1).value = \"Application Details\"\n",
    "            for row in div1s:\n",
    "                label = row.find_element_by_tag_name(\"label\")\n",
    "                label = label.text\n",
    "                para=row.find_element_by_tag_name(\"p\")\n",
    "                para=para.text\n",
    "                row_count = row_count + 1\n",
    "                sheet1.cell(row=row_count, column=1).value = label+para\n",
    "            div2 = driver.find_element_by_id(\"tabContent\")\n",
    "            div2s = div2.find_elements_by_tag_name(\"div\")\n",
    "            row_count=row_count + 1\n",
    "            sheet1.cell(row=row_count, column=1).value = \"Applicant Details\"\n",
    "            for row2 in div2s:\n",
    "                row_count = row_count + 1\n",
    "                label = row.find_element_by_tag_name(\"label\")\n",
    "                label = label.text.strip(\"Comment:\")\n",
    "                sheet1.cell(row=row_count, column=1).value = label+row2.text\n",
    "            workbook.save(\"E:/Web Scrapping/Right Search/Caerphilly/\" + Address + \".xlsx\")\n",
    "            driver.back()\n",
    "        driver.close()\n",
    "        #csv conversion\n",
    "        data = pandas.read_excel(\"E:/Web Scrapping/Right Search/Caerphilly/\" + Address + \".xlsx\",engine='openpyxl')\n",
    "        data.to_csv(\"E:/Web Scrapping/Right Search/Caerphilly/\" + Address + \".csv\", index=None, header=True)\n",
    "        os.remove(\"E:/Web Scrapping/Right Search/Caerphilly/\" + Address + \".xlsx\")\n",
    "        return 0\n",
    "    except Exception as e:\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "41ca590f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ceredigion(Address, website):\n",
    "    try:\n",
    "        # browser\n",
    "        driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "        print(Fore.LIGHTYELLOW_EX+\"Loading...\")\n",
    "        driver.get(\"https://www.ceredigion.gov.uk/resident/planning-building-control-and-sustainable-drainage-body-sab/planning-building-control/planning-applications/\")\n",
    "        driver.implicitly_wait(10)\n",
    "        time.sleep(5)\n",
    "        wait = WebDriverWait(driver, 200)\n",
    "        launch = wait.until(EC.element_to_be_clickable((By.XPATH, \"//*[@id='innerwrapper']/section[2]/div/div/div[1]/p[3]/a\")))\n",
    "        launch.click()\n",
    "        time.sleep(3)\n",
    "        search = wait.until(EC.element_to_be_clickable((By.XPATH, \"//*[@id='content']/div/div/div/div[5]/div/div[2]/div[2]/div[1]/a\")))\n",
    "        search.click()\n",
    "        time.sleep(3)\n",
    "        sitetext = wait.until(EC.element_to_be_clickable((By.ID, \"site_address_description\")))\n",
    "        sitetext.click()\n",
    "        sitetext.send_keys(Address)\n",
    "        time.sleep(3)\n",
    "        search = wait.until(EC.element_to_be_clickable((By.XPATH, \"//*[@id='form']/div[14]/div/div/button[1]\")))\n",
    "        search.click()\n",
    "        table = wait.until(EC.element_to_be_clickable((By.XPATH, \"//*[@id='widget-grid']/div/article/div/div/div[2]/div/table\")))\n",
    "        trs = table.find_elements_by_tag_name('tr')\n",
    "        count = 0\n",
    "        for b in trs:\n",
    "            count = count + 1\n",
    "        # for excel output\n",
    "        workbook = Workbook()\n",
    "        sheet1 = workbook.active\n",
    "        sheet1.title = \"sheet 1\"\n",
    "        row_count = 1\n",
    "        sheet1.cell(row=row_count, column=1).value = \"Property Address:\" + Address\n",
    "        for a in range(1, count):\n",
    "            sheet1.cell(row=row_count, column=1).value =\"_____Result\"+str(a)+\"_____\"\n",
    "            view = driver.find_element_by_xpath( \"//*[@id='widget-grid']/div/article/div/div/div[2]/div/table/tbody/tr[\" + str(a) + \"]/td[8]/button\")\n",
    "            view.click()\n",
    "            time.sleep(15)\n",
    "            driver.switch_to.window(driver.window_handles[a])\n",
    "            popup = driver.find_element_by_xpath(\"//*[@id='application_details']/div/div[2]\")\n",
    "            divs = popup.find_elements_by_class_name(\"col-md-6\")\n",
    "            for div in divs:\n",
    "                rows = div.find_elements_by_tag_name('div')\n",
    "                for row in rows:\n",
    "                    classname = row.get_attribute(\"class\")\n",
    "                    if \"row pad-bottom-5\" in classname:\n",
    "                        innerrows = row.find_elements_by_tag_name('div')\n",
    "                        str1 = \"\"\n",
    "                        for i in innerrows:\n",
    "                            str1 = str1 + (i.text)\n",
    "                        row_count = row_count + 1\n",
    "                        sheet1.cell(row=row_count, column=1).value = str1\n",
    "            workbook.save(\"C:/Users/Vidhya/Desktop/Rightsearchoutput/Ceredigion/\" + Address + \".xlsx\")\n",
    "            driver.switch_to.window(driver.window_handles[0])\n",
    "            time.sleep(2)\n",
    "        driver.quit()\n",
    "        # csv conversion\n",
    "        data = pandas.read_excel(\"E:/Web Scrapping/Right Search/Caerphilly/\" + Address + \".xlsx\",engine='openpyxl')\n",
    "        data.to_csv(\"E:/Web Scrapping/Right Search/Caerphilly/\" + Address + \".csv\", index=None,header=True)\n",
    "        os.remove(\"E:/Web Scrapping/Right Search/Caerphilly/\" + Address + \".xlsx\")\n",
    "        return 0\n",
    "    except Exception as e:\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6eb6c0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[97m55 Clos Yr Eryr, Bridgend, CF35 6HE\u001b[31m -Postal code of this address not found in the list\n",
      "\u001b[97mCartref, Pentre Llyn, Llanilar, Aberystwyth, SY23 4NS\u001b[31m -Postal code of this address not found in the list\n",
      "\u001b[97m79 Clayton Drive, Pontarddulais, Swansea, SA4 8AG\u001b[31m -Postal code of this address not found in the list\n"
     ]
    }
   ],
   "source": [
    "for count in range(14, rows_count + 1):\n",
    "    # fetching input address from excel\n",
    "    Address = propertysheet.cell(row=count, column=1).value\n",
    "    postalcode=findpostal1(Address)  #extracting postalcode from address\n",
    "    if postalcode == 0:\n",
    "        print(Fore.LIGHTWHITE_EX+str(count)+Address+Fore.RED+\" -Postal Code not found! Please Check the address...\")\n",
    "    elif(str(postalcode).isalnum()==False):\n",
    "        print(Fore.LIGHTWHITE_EX+str(count)+Address+Fore.RED+\" -\"+str(postalcode))\n",
    "    else:\n",
    "        website=findweblink(postalcode)\n",
    "        if(website==0):\n",
    "            print(Fore.LIGHTWHITE_EX+Address+Fore.RED+\" -Postal code of this address not found in the list\")\n",
    "        else:\n",
    "            if(website.strip() == \"http://ishare.cardiff.gov.uk/\"):\n",
    "                result=cardiff(Address,website)\n",
    "                resultt(count,result,Address)\n",
    "            elif(website.strip() == \"https://planningonline.torfaen.gov.uk/\"):\n",
    "                result=torfaen(Address,website)\n",
    "                resultt(count, result, Address)\n",
    "            elif(website.strip() == \"https://planningonline.npt.gov.uk/online-applications/\"):\n",
    "                result = npt(Address, website)\n",
    "                resultt(count, result, Address)\n",
    "            elif(website.strip() == \"https://pa.powys.gov.uk/online-applications/?lang=EN\"):\n",
    "                result = powys(Address, website)\n",
    "                resultt(count, result, Address)\n",
    "            elif(website.strip() == \"https://publicaccess.caerphilly.gov.uk/PublicAccess/\"):\n",
    "                result = caerphilly(Address, website)\n",
    "                resultt(count, result, Address)\n",
    "            elif(website.strip() == \"https://my.rctcbc.gov.uk/myRhondda.aspx?MapSource=RCT/AllMaps_english&amp;StartEasting=299818&amp;StartN\"):\n",
    "                result = rhondaa(Address, website)\n",
    "                resultt(count, result, Address)\n",
    "            elif(website.strip() == \"https://maps.monmouthshire.gov.uk/localinfo.aspx\"):\n",
    "                result = monmouthshire(Address, website)\n",
    "                resultt(count, result, Address)\n",
    "            elif(website.strip()==\"http://planning.bridgend.gov.uk/\"):\n",
    "                result =bridgend(Address, website)\n",
    "                resultt(count, result, Address)\n",
    "            elif(website.strip()==\"https://my.newport.gov.uk/myNewport.aspx\"):\n",
    "                result = newport(Address, website)\n",
    "                resultt(count, result, Address)\n",
    "            elif(website.strip()==\"https://myvale.valeofglamorgan.gov.uk/mycouncil.aspx\"):\n",
    "                result = glamorgan(Address, website)\n",
    "                resultt(count, result, Address)\n",
    "            elif(website.strip()==\"https://publicaccess.merthyr.gov.uk/online-applications/\"):\n",
    "                result =merthyrTydfill(Address, website)\n",
    "                resultt(count, result, Address)\n",
    "            elif(website.strip()==\"https://property.swansea.gov.uk/online-applications\"):\n",
    "                result =swansea(Address, website)\n",
    "                resultt(count, result, Address)\n",
    "            elif(website.strip()==\"http://planning.pembrokeshire.gov.uk/swiftlg/apas/run/wphappcriteria.display\"):\n",
    "                result =pembrokeshire(Address, website)\n",
    "                resultt(count, result, Address)\n",
    "            elif(website.strip()==\"https://www.ceredigion.gov.uk/resident/planning-building-control-and-sustainable-drainage-body-sab/planning-building-control/planning-applications/\"):\n",
    "                result =ceredigion(Address, website)\n",
    "                resultt(count, result, Address)\n",
    "            else:\n",
    "                result =carmarthenshire(Address, website)\n",
    "                resultt(count, result, Address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ed8a1049",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 98.0.4758\n",
      "Get LATEST chromedriver version for 98.0.4758 google-chrome\n",
      "Driver [C:\\Users\\yaraz\\.wdm\\drivers\\chromedriver\\win32\\98.0.4758.102\\chromedriver.exe] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mLoading...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NameError(\"name 'WebDriverWait' is not defined\")"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swansea('Ffynone Swansea', \"https://property.swansea.gov.uk/online-applications\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f04fbcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def caerphilly(Address, website):\n",
    "    try:\n",
    "        driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "        driver.get(website)\n",
    "        driver.maximize_window()\n",
    "        print(Fore.LIGHTYELLOW_EX+\"Loading...\")\n",
    "        driver.implicitly_wait(10)\n",
    "        time.sleep(5)\n",
    "        # browser\n",
    "        wait = WebDriverWait(driver, 150)\n",
    "        element = wait.until(EC.element_to_be_clickable((By.ID, \"simpleSearchString\")))\n",
    "        time.sleep(8)\n",
    "        element.click()\n",
    "        time.sleep(4)\n",
    "        element.send_keys(Address)\n",
    "        element2 = wait.until(EC.element_to_be_clickable((By.XPATH, \"//*[@id='simpleSearchForm']/div[3]/input[3]\")))\n",
    "        element2.click()  # find\n",
    "        # for excel output\n",
    "        workbook = Workbook()\n",
    "        sheet1 = workbook.active\n",
    "        sheet1.title = \"sheet 1\"\n",
    "        row_count = 1\n",
    "        sheet1.cell(row=row_count, column=1).value = \"Property Address:\" + Address\n",
    "        row_count=row_count+1\n",
    "        sheet1.cell(row=row_count, column=1).value = \"_____Summary_____\"\n",
    "        #summary\n",
    "        element4 = wait.until(EC.element_to_be_clickable((By.ID, \"simpleDetailsTable\")))\n",
    "        table_rows = element4.find_elements_by_tag_name(\"tr\")\n",
    "        Listy = [\"Reference\", \"Address\", \"Proposal\", \"Status\", \"Decision\", \"Decision Issued Date\", \"Appeal Status\",\"Appeal Decision\"]\n",
    "        for tr in table_rows:\n",
    "            thead = tr.find_element_by_tag_name(\"th\").text\n",
    "            if thead in Listy:\n",
    "                tbody = tr.find_element_by_tag_name(\"td\").text\n",
    "                row_count = row_count + 1\n",
    "                sheet1.cell(row=row_count, column=1).value = thead+\":\"+tbody\n",
    "        row_count = row_count + 1\n",
    "        sheet1.cell(row=row_count, column=1).value = \"_____Important dates_____\"\n",
    "        element3 = wait.until(EC.element_to_be_clickable((By.ID, \"subtab_dates\")))\n",
    "        element3.click()  # find\n",
    "        # extracting details\n",
    "        element4 = wait.until(EC.element_to_be_clickable((By.ID, \"simpleDetailsTable\")))\n",
    "        table_rows = element4.find_elements_by_tag_name(\"tr\")\n",
    "        Listy=[\"Application Received Date\",\"Application Validated Date\",\"Decision Made Date\",\"Decision Issued Date\",\"Decision Printed Date\",\"Temporary Permission Expiry Date\"]\n",
    "        for tr in table_rows:\n",
    "            row_count = row_count + 1\n",
    "            thead = tr.find_element_by_tag_name(\"th\").text\n",
    "            if thead in Listy:\n",
    "                tbody = tr.find_element_by_tag_name(\"td\").text\n",
    "                sheet1.cell(row=row_count, column=1).value = thead+\":\"+tbody\n",
    "        address = Address.strip()\n",
    "        workbook.save(\"E:/Web Scrapping/Right Search/Caerphilly/\" + address + \".xlsx\")\n",
    "        driver.close()\n",
    "        #csv conversion\n",
    "        data = pandas.read_excel(\"E:/Web Scrapping/Right Search/Caerphilly/\" + Address + \".xlsx\",engine='openpyxl')\n",
    "        data.to_csv(\"E:/Web Scrapping/Right Search/Caerphilly/\" + Address + \".csv\", index=None, header=True)\n",
    "        os.remove(\"E:/Web Scrapping/Right Search/Caerphilly/\" + Address + \".xlsx\")\n",
    "        return 0\n",
    "    except Exception as e:\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c2879b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 98.0.4758\n",
      "Get LATEST chromedriver version for 98.0.4758 google-chrome\n",
      "Driver [C:\\Users\\yaraz\\.wdm\\drivers\\chromedriver\\win32\\98.0.4758.102\\chromedriver.exe] found in cache\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "selenium.common.exceptions.InvalidArgumentException(\"invalid argument: 'url' must be a string\\n  (Session info: chrome=98.0.4758.102)\",\n",
       "                                                    None,\n",
       "                                                    None)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caerphilly(Address, website)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
